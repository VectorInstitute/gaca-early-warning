{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7dca4f2-3bc0-4084-b939-baed47457fff",
   "metadata": {},
   "source": [
    "### helper notebook to show how to generate maps based off of preds.csv after running the pipeline\n",
    "\n",
    "authored nov 14, 2025 by jelshawa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b8b53-eff2-444d-934e-b9a028dd945e",
   "metadata": {},
   "source": [
    "#### context\n",
    "to run the pipeline and generate predictions starting from the latest noaa recorded time, execute this command\n",
    "> !python main.py --config config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9164299c-0284-48ad-b36e-826a86745603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:20:13,979 â€” INFO â€” ğŸ”¥ starting inference pipeline!\n",
      "2025-11-17 15:20:13,980 â€” INFO â€” ğŸ“‚ run dir: ./TEST\n",
      "2025-11-17 15:20:13,980 â€” INFO â€” ğŸ“¦ loading pretrained artifacts...\n",
      "/Users/amritkrishnan/src/gaca-early-warning/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2025-11-17 15:20:25,979 â€” INFO â€” ğŸ§  loading trained model weights...\n",
      "2025-11-17 15:20:25,984 â€” INFO â€” ğŸ”§ using patched model_args: {'in_channels': 8, 'out_channels': 1, 'hidden_dim': 32, 'pred_horizons': 7, 'num_nodes': 14005}\n",
      "2025-11-17 15:20:26,010 â€” INFO â€” loaded model GCNGRU with args: {'in_channels': 8, 'out_channels': 1, 'hidden_dim': 32, 'pred_horizons': 7, 'num_nodes': 14005}\n",
      "2025-11-17 15:20:26,010 â€” INFO â€” in main extraction func, hours: 24, lat min: 42.0\n",
      "2025-11-17 15:20:26,306 â€” INFO â€” ğŸŒŸ latest available urma timestamp: 2025-11-17 13:00:00\n",
      "2025-11-17 15:21:22,292 â€” INFO â€” [â±ï¸ Load NOAA data] took 56.28 sec\n",
      "2025-11-17 15:21:22,292 â€” INFO â€” \n",
      "====================== âœ… extraction successful ======================\n",
      "2025-11-17 15:21:22,292 â€” INFO â€” ğŸ§ª loaded df with shape: (336120, 9)\n",
      "2025-11-17 15:21:22,292 â€” INFO â€” total rows extracted: 336120\n",
      "2025-11-17 15:21:22,292 â€” INFO â€” latest timestamp: 2025-11-17 13:00:00\n",
      "2025-11-17 15:21:22,302 â€” INFO â€” num unique locations: 14005\n",
      "2025-11-17 15:21:22,302 â€” INFO â€” timestamps: 2025-11-16 14:00:00 â†’ 2025-11-17 13:00:00\n",
      "2025-11-17 15:21:22,303 â€” INFO â€” starting preprocessing for inference!\n",
      "2025-11-17 15:21:22,303 â€” INFO â€” feats to be used: ['t2m', 'd2m', 'u10', 'v10', 'sp', 'orog']\n",
      "celsius: True\n",
      "2025-11-17 15:21:22,303 â€” INFO â€” loading graph!\n",
      "2025-11-17 15:21:22,319 â€” INFO â€” now building per-timestamp feature sequecne\n",
      "2025-11-17 15:21:22,410 â€” INFO â€” ğŸ§  generated 24 temporal snapshots\n",
      "2025-11-17 15:21:22,412 â€” INFO â€” ğŸ§® Total NaNs in sequence: 0\n",
      "2025-11-17 15:21:22,412 â€” INFO â€” âœ… NO nans detected in data!\n",
      "2025-11-17 15:21:22,418 â€” INFO â€” ğŸ“ final per-hour feature shape: (14005, 8)\n",
      "2025-11-17 15:21:22,423 â€” INFO â€” [â±ï¸ Preprocessing] took 0.12 sec\n",
      "2025-11-17 15:21:22,423 â€” INFO â€” ğŸ“ model input shape: torch.Size([1, 24, 14005, 8])\n",
      "2025-11-17 15:21:22,574 â€” INFO â€” [â±ï¸ Model run] took 0.15 sec\n",
      "2025-11-17 15:21:22,574 â€” INFO â€” preds shape: (1, 7, 14005, 1)\n",
      "2025-11-17 15:21:22,575 â€” INFO â€” sample preds: [[ 4.8005037]\n",
      " [ 5.4208364]\n",
      " [ 7.560724 ]\n",
      " [ 6.702696 ]\n",
      " [ 6.4384236]\n",
      " [10.456446 ]\n",
      " [ 8.885765 ]]\n",
      "2025-11-17 15:21:24,148 â€” INFO â€” saved inference results â†’ ./TEST/predictions.csv\n",
      "2025-11-17 15:21:24,152 â€” INFO â€” generating gnn-style inference maps...\n",
      "2025-11-17 15:21:24,729 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots/maps/spatial_2025-11-17_14-00_plus1h.png\n",
      "2025-11-17 15:21:24,867 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots/maps/spatial_2025-11-17_19-00_plus6h.png\n",
      "2025-11-17 15:21:25,007 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots/maps/spatial_2025-11-18_01-00_plus12h.png\n",
      "2025-11-17 15:21:25,146 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots/maps/spatial_2025-11-18_07-00_plus18h.png\n",
      "2025-11-17 15:21:25,282 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots/maps/spatial_2025-11-18_13-00_plus24h.png\n",
      "2025-11-17 15:21:25,417 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots/maps/spatial_2025-11-19_01-00_plus36h.png\n",
      "2025-11-17 15:21:25,554 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots/maps/spatial_2025-11-19_13-00_plus48h.png\n",
      "2025-11-17 15:21:25,554 â€” INFO â€” generating timeseries plots...\n",
      "2025-11-17 15:21:25,607 â€” INFO â€” ğŸ“Œ saved mean-timeseries â†’ ./TEST/plots/timeseries/mean_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:25,659 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots/timeseries/node_1775_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:25,708 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots/timeseries/node_13855_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:25,756 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots/timeseries/node_2290_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:25,805 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots/timeseries/node_1150_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:25,852 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots/timeseries/node_12270_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:25,852 â€” INFO â€” ğŸ–¼ï¸ plots generated!\n",
      "2025-11-17 15:21:25,852 â€” INFO â€” ğŸ‰ inference completed successfully!\n",
      "CPU times: user 852 ms, sys: 233 ms, total: 1.08 s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python main.py --config config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb63473-9f40-4264-bd47-7327c23af1d2",
   "metadata": {},
   "source": [
    "#### imports + helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27672268-b1ff-471e-94ec-38eb09c237e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebook helper imports for generating visualization maps from predictions CSV.\"\"\"\n",
    "import os\n",
    "from argparse import Namespace\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from util.plotting import plot_inference_maps, plot_prediction_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd60b9b-c28f-42ac-a6da-da713adf4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from YAML file and convert to Namespace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config_path : str\n",
    "        Path to the YAML configuration file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    argparse.Namespace\n",
    "        Configuration as a nested Namespace object with dotted-notation access.\n",
    "    \"\"\"\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    def to_namespace(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            ns = Namespace()\n",
    "            for k, v in obj.items():\n",
    "                setattr(ns, k, to_namespace(v))\n",
    "            return ns\n",
    "        return obj\n",
    "\n",
    "    return to_namespace(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b46f91-f4e6-4bce-b282-62371a81dba3",
   "metadata": {},
   "source": [
    "#### main setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaadb729-de72-43d3-9de7-cc773adbff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_config(\"./config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a175643f-bdee-4510-b636-36938aff4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_csv_path = args.graph.nodes_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f92e46-22f9-4ae4-9088-8eba4a34dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded preds csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_time</th>\n",
       "      <th>horizon_hours</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>predicted_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-17 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000080</td>\n",
       "      <td>-80.84195</td>\n",
       "      <td>4.800504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-17 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000153</td>\n",
       "      <td>-78.74701</td>\n",
       "      <td>-2.585595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-17 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000496</td>\n",
       "      <td>-79.24889</td>\n",
       "      <td>-1.385997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-17 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000782</td>\n",
       "      <td>-78.51062</td>\n",
       "      <td>-2.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-17 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>42.001110</td>\n",
       "      <td>-78.27423</td>\n",
       "      <td>-1.289757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         forecast_time  horizon_hours        lat       lon  predicted_temp\n",
       "0  2025-11-17 14:00:00              1  42.000080 -80.84195        4.800504\n",
       "1  2025-11-17 14:00:00              1  42.000153 -78.74701       -2.585595\n",
       "2  2025-11-17 14:00:00              1  42.000496 -79.24889       -1.385997\n",
       "3  2025-11-17 14:00:00              1  42.000782 -78.51062       -2.862100\n",
       "4  2025-11-17 14:00:00              1  42.001110 -78.27423       -1.289757"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load preds csv\n",
    "pred_csv_path = f\"{args.run_dir}/predictions.csv\"\n",
    "df_pred = pd.read_csv(pred_csv_path)\n",
    "\n",
    "print(\"loaded preds csv:\")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611ac14c-a38e-4741-860d-fd435f5ff0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizons (H): 7\n",
      "nodes (N): 14005\n"
     ]
    }
   ],
   "source": [
    "# get num of horizons from csv\n",
    "pred_offsets = sorted(df_pred[\"horizon_hours\"].unique().tolist())\n",
    "H = len(pred_offsets)\n",
    "\n",
    "# get num of nodes\n",
    "unique_nodes = df_pred[[\"lat\", \"lon\"]].drop_duplicates()\n",
    "N = len(unique_nodes)\n",
    "\n",
    "print(f\"horizons (H): {H}\")\n",
    "print(f\"nodes (N): {N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bbc035-8472-4032-a8e1-c7c1ba52bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tensor = np.zeros((1, H, N, 1), dtype=np.float32)\n",
    "\n",
    "# sort df by horizon + (lat, lon)\n",
    "df_sorted = df_pred.sort_values([\"horizon_hours\", \"lat\", \"lon\"]).reset_index(drop=True)\n",
    "\n",
    "for h_idx, horizon in enumerate(pred_offsets):\n",
    "    df_h = df_sorted[df_sorted[\"horizon_hours\"] == horizon]\n",
    "    pred_tensor[0, h_idx, :, 0] = df_h[\"predicted_temp\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b4c355-f8c4-48fa-965e-f868045ebbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1, 7, 14005, 1)\n"
     ]
    }
   ],
   "source": [
    "# double check shape, should be (batch_size, # horizons, # nodes, output dim)\n",
    "preds_unscaled_from_csv = pred_tensor\n",
    "print(f\"Shape: {preds_unscaled_from_csv.shape}\")\n",
    "# so for current setup should be (1, 7, 14005, 1)\n",
    "# bc only doing one 'sequence', for 7 horizons, have 14005 nodes, and\n",
    "# 1 pred for each node per horizon (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d912262-77b5-4272-bb03-21d8ecbd6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that num nodes match our nodes df\n",
    "nodes_df = pd.read_csv(nodes_csv_path)\n",
    "nodes_df = nodes_df.sort_values([\"lat\", \"lon\"]).reset_index(drop=True)\n",
    "assert len(nodes_df) == N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "090443a5-2ff1-4590-ae9d-ac39226d96ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recovered latest_timestamp: 2025-11-17 13:00:00\n"
     ]
    }
   ],
   "source": [
    "# get latest timestamp that we used for generating the predictions\n",
    "h_min = int(df_pred[\"horizon_hours\"].min())  # min of the horizons\n",
    "t_forecast_0 = pd.to_datetime(df_pred[\"forecast_time\"]).min()  # min of the timestamps\n",
    "\n",
    "latest_timestamp = t_forecast_0 - timedelta(\n",
    "    hours=h_min\n",
    ")  # latest ts = min of the timestamps - min horizon time\n",
    "\n",
    "print(\"recovered latest_timestamp:\", latest_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4978e-47dd-4214-9191-3d53b3fcc1de",
   "metadata": {},
   "source": [
    "#### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbafe06-3b2f-41e5-9c2d-f58e23039e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating spatial inference maps from csv...\n",
      "2025-11-17 15:21:27,204 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots_from_csv/maps/spatial_2025-11-17_14-00_plus1h.png\n",
      "2025-11-17 15:21:27,341 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots_from_csv/maps/spatial_2025-11-17_19-00_plus6h.png\n",
      "2025-11-17 15:21:27,478 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots_from_csv/maps/spatial_2025-11-18_01-00_plus12h.png\n",
      "2025-11-17 15:21:27,631 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots_from_csv/maps/spatial_2025-11-18_07-00_plus18h.png\n",
      "2025-11-17 15:21:27,768 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots_from_csv/maps/spatial_2025-11-18_13-00_plus24h.png\n",
      "2025-11-17 15:21:27,905 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots_from_csv/maps/spatial_2025-11-19_01-00_plus36h.png\n",
      "2025-11-17 15:21:28,042 â€” INFO â€” ğŸ“Œ saved spatial map â†’ ./TEST/plots_from_csv/maps/spatial_2025-11-19_13-00_plus48h.png\n"
     ]
    }
   ],
   "source": [
    "# create plot dir\n",
    "plot_dir = f\"{args.run_dir}/plots_from_csv\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# plot spatial maps\n",
    "print(\"generating spatial inference maps from csv...\")\n",
    "plot_inference_maps(\n",
    "    preds_unscaled=preds_unscaled_from_csv,\n",
    "    nodes_df=nodes_df,\n",
    "    pred_offsets=pred_offsets,\n",
    "    out_dir=os.path.join(plot_dir, \"maps\"),\n",
    "    latest_timestamp=latest_timestamp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "366f76f7-8aab-4cc1-ad69-06778bceb6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating timeseries plots from csv...\n",
      "2025-11-17 15:21:28,094 â€” INFO â€” ğŸ“Œ saved mean-timeseries â†’ ./TEST/plots_from_csv/timeseries/mean_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:28,142 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots_from_csv/timeseries/node_9928_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:28,187 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots_from_csv/timeseries/node_7976_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:28,237 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots_from_csv/timeseries/node_5545_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:28,283 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots_from_csv/timeseries/node_12972_timeseries_20251117_1300.png\n",
      "2025-11-17 15:21:28,329 â€” INFO â€” ğŸ“Œ saved node-timeseries â†’ ./TEST/plots_from_csv/timeseries/node_6527_timeseries_20251117_1300.png\n"
     ]
    }
   ],
   "source": [
    "# plot timeseries\n",
    "print(\"generating timeseries plots from csv...\")\n",
    "plot_prediction_timeseries(\n",
    "    preds_unscaled=preds_unscaled_from_csv,\n",
    "    pred_offsets=pred_offsets,\n",
    "    out_dir=os.path.join(plot_dir, \"timeseries\"),\n",
    "    latest_timestamp=latest_timestamp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a37f9f-164f-4e24-aa6a-6784fc9984fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
